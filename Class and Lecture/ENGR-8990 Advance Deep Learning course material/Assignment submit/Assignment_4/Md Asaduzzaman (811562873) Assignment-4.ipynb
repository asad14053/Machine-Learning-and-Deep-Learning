{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjhrQUU41dqA"
      },
      "source": [
        "#ENGR 8990 - Deep Learning & Engineering Applications\n",
        "## Assignment 4 - Transformer for Sentiment Classification \n",
        "In this assignment, you will code a transformer model for sentiment classification.\n",
        "\n",
        "1.   Construct a transformer encoder (you could use the one in NB13) as the backbone and add a linear classifier for sentiment classification using the IMDB dataset (note: the vocab for IMDB is different from the NMT dataset used in NB13).\n",
        "\n",
        "2.   Train the model and display the proggess showing both training and validation metrics.\n",
        "\n",
        "2.   Evaluate the trained model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKnisqY213T6"
      },
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "import torch.nn.functional as f\n",
        "import numpy as np\n",
        "import torchtext.legacy.data as data\n",
        "import torchtext.legacy.datasets as datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_zHSTeb46ck"
      },
      "source": [
        "## Download the IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txCzTgDd1-Gv",
        "outputId": "58124375-aa56-4e8e-a46a-39db0195bd79"
      },
      "source": [
        "max_len = 200\n",
        "text = data.Field(sequential=True, fix_length=max_len, batch_first=True, lower=True, dtype=torch.long)\n",
        "label = data.LabelField(sequential=False, dtype=torch.long)\n",
        "datasets.IMDB.download('./')\n",
        "ds_train, ds_test = datasets.IMDB.splits(text, label, path='./imdb/aclImdb/')\n",
        "print('train : ', len(ds_train))\n",
        "print('test : ', len(ds_test))\n",
        "print('train.fields :', ds_train.fields)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  25000\n",
            "test :  25000\n",
            "train.fields : {'text': <torchtext.legacy.data.field.Field object at 0x7f1cac5d9ad0>, 'label': <torchtext.legacy.data.field.LabelField object at 0x7f1cac5d9b50>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWs2u1MQ5BdZ"
      },
      "source": [
        "## Split the training dataset into train set and valid set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_raNfY42LFu",
        "outputId": "d68e792b-2f4a-4eef-82ea-6c6e7e1f1bc3"
      },
      "source": [
        "ds_train, ds_valid = ds_train.split(0.9)\n",
        "print('train : ', len(ds_train))\n",
        "print('valid : ', len(ds_valid))\n",
        "print('test : ', len(ds_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  22500\n",
            "valid :  2500\n",
            "test :  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYjwdbWt2Sjt"
      },
      "source": [
        "num_words = 50000\n",
        "text.build_vocab(ds_train, max_size=num_words)\n",
        "label.build_vocab(ds_train)\n",
        "vocab = text.vocab"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgur9LIU2WKJ"
      },
      "source": [
        "batch_size = 64\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (ds_train, ds_valid, ds_test), batch_size=batch_size, sort_key=lambda x: len(x.text), repeat=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8IrHMbMPM90",
        "outputId": "25d0ac1a-5c54-4307-b61b-ef2c487bce73"
      },
      "source": [
        "train_iterator, valid_iterator = iter(train_loader), iter(valid_loader)\n",
        "for batch in train_iterator:\n",
        "    print (batch.text, batch.label)\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6811, 2725, 6237,  ...,  263,  734,   31],\n",
            "        [1986,  276,   10,  ..., 1219,   17,   21],\n",
            "        [   9,   61,   37,  ..., 4146,    1,    1],\n",
            "        ...,\n",
            "        [ 200,   10,    3,  ...,    1,    1,    1],\n",
            "        [ 133,    2,   75,  ...,   48,  145,  650],\n",
            "        [  26,    6, 4702,  ...,    1,    1,    1]]) tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
            "        0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
            "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCDutHlconrd"
      },
      "source": [
        "# Code will start here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1HnpikHulUN"
      },
      "source": [
        "# a) Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSNVLu1Ljxve"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "# Reference: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98mL6CqD2Szr",
        "outputId": "b037de61-27f2-400f-edeb-330e6ac01c67"
      },
      "source": [
        "\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:06<00:00, 13.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hFzB4rTj-n9",
        "outputId": "bc2b03fd-bc69-47a4-a5d6-fd8dad0e537a"
      },
      "source": [
        "# Print the train/train data set\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "{'text': ['Masters', 'of', 'Horror', ':', 'Right', 'to', 'Die', 'starts', 'late', 'one', 'night', 'as', 'married', 'couple', 'Abby', '(', 'Julia', 'Anderson', ')', '&', 'Ciff', 'Addison', '(', 'Martin', 'Donovan', ')', 'are', 'driving', 'home', ',', 'however', 'while', 'talking', 'Cliff', 'is', 'distracted', '&', 'crashes', 'into', 'a', 'tree', 'that', 'has', 'fallen', 'across', 'the', 'road', '.', 'Cliff', \"'s\", 'airbag', 'works', 'OK', '&', 'he', 'walks', 'away', 'with', 'minor', 'injuries', ',', 'unfortunately', 'for', 'Abby', 'hers', 'did', \"n't\", '&', 'she', 'ended', 'up', 'as', 'toast', 'when', 'she', 'was', 'thrown', 'from', 'the', 'car', '&', 'doused', 'in', 'petrol', 'which', 'set', 'alight', 'burning', 'her', 'entire', 'body', '.', 'Abby', \"'s\", 'life', 'is', 'saved', ',', 'just', '.', 'She', 'is', 'taken', 'to', 'hospital', 'where', 'she', 'is', 'on', 'life', 'support', 'seriously', 'injured', '&', 'horribly', 'disfigured', 'from', 'the', 'burns', '.', 'Cliff', 'decides', 'that', 'she', 'should', 'die', ',', 'his', 'selfish', 'lawyer', 'Ira', '(', 'Corbin', 'Bersen', ')', 'thinks', 'they', 'should', 'let', 'Abby', 'die', ',', 'sue', 'the', 'car', 'manufacturer', '&', 'get', 'rich', 'while', 'Abby', \"'s\", 'mum', 'Pam', '(', 'Linda', 'Sorenson', ')', 'wants', 'to', 'blame', 'Cliff', ',', 'get', 'rich', '&', 'save', 'Abby', '.', 'However', 'Abby', 'has', 'other', 'plans', 'of', 'her', 'own', '...', '<br', '/><br', '/>This', 'American', 'Canadian', 'co', '-', 'production', 'was', 'directed', 'by', 'Rob', 'Schmidt', '(', 'whose', 'only', 'horror', 'film', 'previously', 'was', 'Wrong', 'Turn', '(', '2003', ')', 'which', 'on', 'it', \"'s\", 'own', 'hardly', 'qualifies', 'him', 'to', 'direct', 'a', 'Masters', 'of', 'Horror', 'episode', ')', '&', 'was', 'episode', '9', 'from', 'season', '2', 'of', 'the', 'Masters', 'of', 'Horror', 'TV', 'series', ',', 'while', 'I', 'did', \"n't\", 'think', 'Right', 'to', 'Die', 'was', 'the', 'best', 'Masters', 'of', 'Horror', 'episode', 'I', \"'ve\", 'seen', 'I', 'thought', 'it', 'was', 'a', 'decent', 'enough', 'effort', 'all', 'the', 'same', '&', 'still', 'does', \"n't\", 'come', 'close', 'to', 'being', 'as', 'bad', 'as', 'The', 'Screwfly', 'Solution', '(', '2006', ')', '.', 'The', 'script', 'by', 'John', 'Esposito', 'has', 'a', 'neat', 'central', 'idea', 'that', 'is', \"n't\", 'anything', 'new', 'but', 'it', 'uses', 'it', 'effectively', 'enough', 'although', 'I', \"'d\", 'say', 'it', \"'s\", 'a', 'bit', 'uneven', ',', 'the', 'first', '15', 'minutes', 'of', 'this', 'focuses', 'on', 'the', 'horror', 'element', 'of', 'the', 'story', 'but', 'then', 'it', 'goes', 'into', 'a', 'lull', 'for', '20', 'odd', 'minutes', 'as', 'it', 'becomes', 'a', 'drama', 'as', 'the', 'legal', 'wrangling', 'over', 'Abby', \"'s\", 'life', '&', 'the', 'affair', 'Cliff', 'is', 'having', 'take', 'center', 'stage', 'before', 'it', 'gets', 'back', 'on', 'track', 'it', 'a', 'deliciously', 'gory', '&', 'twisted', 'climax', 'that', 'may', 'not', 'be', 'for', 'the', 'faint', 'of', 'heart', '.', 'The', 'character', \"'s\", 'are', 'a', 'bit', 'clichéd', ',', 'the', 'weak', 'man', ',', 'the', 'bent', 'lawyer', ',', 'the', 'protective', 'mum', '&', 'the', 'young', 'tart', 'who', 'has', 'sex', 'to', 'get', 'what', 'she', 'wants', 'but', 'they', 'all', 'serve', 'their', 'purpose', 'well', 'enough', ',', 'the', 'dialogue', 'is', 'OK', ',', 'the', 'story', 'moves', 'along', 'at', 'a', 'nice', 'pace', '&', 'overall', 'I', 'liked', 'Right', 'to', 'Die', 'apart', 'from', 'a', 'few', 'minutes', 'here', '&', 'there', 'where', 'it', 'loses', 'it', \"'s\", 'focus', 'a', 'bit', '&', 'I', 'was', \"n't\", 'that', 'keen', 'on', 'the', 'ambiguous', 'ending.<br', '/><br', '/>Director', 'Schmidt', 'does', 'a', 'good', 'job', '&', 'there', 'are', 'some', 'effective', 'scenes', ',', 'this', 'tries', 'to', 'alternate', 'between', 'low', 'key', 'spooky', 'atmosphere', '&', 'out', '-', 'and', '-', 'out', 'blood', '&', 'gore', '.', 'There', 'are', 'some', 'fantastic', 'special', 'make', '-', 'up', 'effects', 'as', 'usual', ',', 'there', \"'s\", 'shots', 'of', 'Abby', 'where', 'she', 'has', 'had', 'all', 'of', 'the', 'skin', 'burned', 'off', 'her', 'body', '&', 'the', 'image', 'of', 'her', 'bandaged', 'head', 'with', 'her', 'teeth', 'showing', 'because', 'she', 'has', 'no', 'lips', 'left', 'is', 'pretty', 'gross', '(', 'images', '&', 'make', '-', 'up', 'effects', 'that', 'reminded', 'me', 'of', 'similar', 'scenes', 'in', 'Hellraiser', '(', '1987', ')', '&', 'it', \"'s\", 'sequels', ')', ',', 'then', 'there', \"'s\", 'the', 'main', 'course', 'at', 'the', 'end', 'where', 'Cliff', 'literally', 'skins', 'someone', 'complete', 'with', 'close', '-', 'ups', 'of', 'scalpels', 'slicing', 'skin', 'open', '&', 'him', 'peeling', 'it', 'off', 'the', 'muscle', '&', 'putting', 'it', 'into', 'a', 'cooler', 'box', '!', 'Very', 'messy', '.', 'There', 'are', 'also', 'various', 'assorted', 'body', 'parts', '.', 'There', \"'s\", 'some', 'nudity', 'here', 'as', 'well', 'with', 'at', 'least', 'a', 'couple', 'of', 'pretty', 'ladies', 'getting', 'naked', '...', '<br', '/><br', '/>Technically', 'Right', 'to', 'Die', 'is', 'excellent', ',', 'the', 'special', 'effects', 'are', 'brilliant', '&', 'as', 'most', 'Masters', 'of', 'Horror', 'episodes', 'it', 'does', \"n't\", 'look', 'like', 'a', 'cheap', 'made', '-', 'for', '-', 'TV', 'show', 'which', 'basically', 'if', 'the', 'truth', 'be', 'told', 'it', 'is', '.', 'The', 'acting', 'was', 'fine', 'but', 'there', \"'s\", 'no', 'big', \"'\", 'names', \"'\", 'in', 'this', 'one.<br', '/><br', '/>Right', 'to', 'Die', 'is', 'another', 'enjoyable', '&', 'somewhat', 'twisted', 'Masters', 'of', 'Horror', 'episode', 'that', 'most', 'horror', 'fans', 'should', 'definitely', 'check', 'out', 'if', 'not', 'just', 'for', 'the', 'terrific', 'skinning', 'scene', '!', 'Well', 'worth', 'a', 'watch', '...', 'for', 'those', 'with', 'the', 'stomach', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--utaDYqKCX",
        "outputId": "5fa2f9dd-507f-4cca-8336-ce294f69b603"
      },
      "source": [
        "# Split train data into train and validation data 70:30  ratio\n",
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrA1jraMrEzR",
        "outputId": "6a1c651a-353c-49f4-9e6e-12b2101a8eb9"
      },
      "source": [
        "# Build a unique vocabulary set using token: spacy and  tokenizer_language = en_core_web_sm\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdwjV8cqr0Ta",
        "outputId": "20ec8672-6791-4587-bde6-0d39f33562d9"
      },
      "source": [
        "# Find repetitive words with frequencies\n",
        "\n",
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 201848), (',', 192094), ('.', 165079), ('and', 108918), ('a', 108697), ('of', 100405), ('to', 93109), ('is', 75325), ('in', 61106), ('I', 54354), ('it', 53326), ('that', 48913), ('\"', 44033), (\"'s\", 43177), ('this', 42233), ('-', 36840), ('/><br', 35313), ('was', 35231), ('as', 30149), ('movie', 29894)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-XR8O0HtJHj",
        "outputId": "87812e22-ec3c-4095-9dff-7c2bcc4b377f"
      },
      "source": [
        "# print Vocabulary set in itos and Label\n",
        "# check the labels, ensuring 0 is for negative and 1 is for positive.\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ZUG7PFuYkO"
      },
      "source": [
        "# Prepare batch for training\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wvDu4_7u1KN"
      },
      "source": [
        "# b) Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjjvm0_XlDaQ"
      },
      "source": [
        "#Initialize Model\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed1-kEIzvbP4"
      },
      "source": [
        "# create model instance and define dimensions\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFkNYLxfvq0X",
        "outputId": "8d8199c7-1287-4bf7-9907-3883b92f7821"
      },
      "source": [
        "# Find trainable Parameter\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoB5a6btvy8H"
      },
      "source": [
        "# c) Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOben7kLv9oe"
      },
      "source": [
        "#define optimizer function\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUr0gRY6wOJf"
      },
      "source": [
        "# Define binary cross entropy loss and apply it to the model\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFzmSnIFwhXn"
      },
      "source": [
        "# calculate how many rounded predictions equal the actual labels and average it across the batch\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bJVADtBxBwq"
      },
      "source": [
        "# define train function\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCoIFmBMxUqo"
      },
      "source": [
        "#define validation process\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MklpUrhQxccR"
      },
      "source": [
        "#define timer\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPTxB7AjxisZ",
        "outputId": "83cca67e-79f0-46ab-ce12-7fdbef14750d"
      },
      "source": [
        "# run training and validation process\n",
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 9m 28s\n",
            "\tTrain Loss: 0.694 | Train Acc: 50.10%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.43%\n",
            "Epoch: 02 | Epoch Time: 9m 21s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.90%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.69%\n",
            "Epoch: 03 | Epoch Time: 9m 20s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.91%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.41%\n",
            "Epoch: 04 | Epoch Time: 9m 21s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.72%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.12%\n",
            "Epoch: 05 | Epoch Time: 9m 23s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.97%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXiXfmbl-2w-",
        "outputId": "ef442629-41db-434d-f8f5-366f5a5d0bb2"
      },
      "source": [
        "# Tesing Phase\n",
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.709 | Test Acc: 47.17%\n"
          ]
        }
      ]
    }
  ]
}